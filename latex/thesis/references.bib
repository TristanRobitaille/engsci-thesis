@inproceedings{yao2023cnn,
  title={A cnn-transformer deep learning model for real-time sleep stage classification in an energy-constrained wireless device},
  author={Yao, Zongyan and Liu, Xilin},
  booktitle={2023 11th International IEEE/EMBS Conference on Neural Engineering (NER)},
  pages={1--4},
  year={2023},
  organization={IEEE}
}

@article{liu2021edge,
  title={Edge deep learning for neural implants: a case study of seizure detection and prediction},
  author={Liu, Xilin and Richardson, Andrew G},
  journal={Journal of Neural Engineering},
  volume={18},
  number={4},
  pages={046034},
  year={2021},
  publisher={IOP Publishing}
}

@inproceedings{qi2021accommodating,
  title={Accommodating transformer onto fpga: Coupling the balanced model compression and fpga-implementation optimization},
  author={Qi, Panjie and Song, Yuhong and Peng, Hongwu and Huang, Shaoyi and Zhuge, Qingfeng and Sha, Edwin Hsing-Mean},
  booktitle={Proceedings of the 2021 on Great Lakes Symposium on VLSI},
  pages={163--168},
  year={2021}
}

@inproceedings{li2020ftrans,
  title={Ftrans: energy-efficient acceleration of transformers using fpga},
  author={Li, Bingbing and Pandey, Santosh and Fang, Haowen and Lyv, Yanjun and Li, Ji and Chen, Jieyang and Xie, Mimi and Wan, Lipeng and Liu, Hang and Ding, Caiwen},
  booktitle={Proceedings of the ACM/IEEE International Symposium on Low Power Electronics and Design},
  pages={175--180},
  year={2020}
}

@inproceedings{ding2017circnn,
  title={Circnn: accelerating and compressing deep neural networks using block-circulant weight matrices},
  author={Ding, Caiwen and Liao, Siyu and Wang, Yanzhi and Li, Zhe and Liu, Ning and Zhuo, Youwei and Wang, Chao and Qian, Xuehai and Bai, Yu and Yuan, Geng and others},
  booktitle={Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture},
  pages={395--408},
  year={2017}
}

@article{kumar2022aptx,
  title={APTx: better activation function than MISH, SWISH, and ReLU's variants used in deep learning},
  author={Kumar, Ravin},
  journal={arXiv preprint arXiv:2209.06119},
  year={2022}
}

@article{alizadeh2023llm,
  title={LLM in a flash: Efficient Large Language Model Inference with Limited Memory},
  author={Alizadeh, Keivan and Mirzadeh, Iman and Belenko, Dmitry and Khatamifard, Karen and Cho, Minsik and Del Mundo, Carlo C and Rastegari, Mohammad and Farajtabar, Mehrdad},
  journal={arXiv preprint arXiv:2312.11514},
  year={2023}
}